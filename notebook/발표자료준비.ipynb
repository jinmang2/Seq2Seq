{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Additive Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "SEQ_LEN     = 15\n",
    "BATCH_SIZE  = 5\n",
    "INPUT_DIM   = 30\n",
    "OUTPUT_DIM  = 37\n",
    "HID_DIM     = 256\n",
    "ENC_EMB_DIM = DEC_EMB_DIM = 32\n",
    "ENC_HID_DIM = DEC_HID_DIM = 64\n",
    "ENC_LAYERS  = DEC_LAYERS  = 3\n",
    "ENC_HEADS   = DEC_HEADS   = 8\n",
    "ENC_PF_DIM  = DEC_PF_DIM  = 512\n",
    "ENC_DROPOUT = DEC_DROPOUT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0, 25,  4, 25, 21, 25,  9,  6, 29,  1,  1,  1,  1,  1,  1],\n",
      "        [ 0, 26,  7, 11,  7, 18, 11,  6, 12,  7, 29,  1,  1,  1,  1],\n",
      "        [ 0,  8,  8, 25,  9, 24, 17, 14, 16, 24, 21, 10, 24, 29,  1],\n",
      "        [ 0,  5, 25,  3, 17, 21, 17,  4, 25,  3, 15, 29,  1,  1,  1],\n",
      "        [ 0, 10,  7, 17, 23,  7,  9, 13,  8,  8,  7,  9, 20, 16, 29]]) torch.Size([5, 15])\n",
      "\n",
      "tensor([[ 0, 11, 17, 27,  3, 28, 28, 36,  1,  1,  1,  1,  1,  1,  1],\n",
      "        [ 0, 13, 26, 30,  6, 17,  2, 11, 13, 19, 17, 32, 36,  1,  1],\n",
      "        [ 0, 33, 24, 32,  7, 30, 36,  1,  1,  1,  1,  1,  1,  1,  1],\n",
      "        [ 0, 13, 19, 34, 21,  9, 27, 15, 36,  1,  1,  1,  1,  1,  1],\n",
      "        [ 0, 28, 22, 15,  9, 20, 11, 27, 16,  7, 25,  7, 20, 22, 36]]) torch.Size([5, 15])\n"
     ]
    }
   ],
   "source": [
    "SRC_PAD_IDX = TRG_PAD_IDX = 1\n",
    "MIN_WORDS   = 5\n",
    "\n",
    "src_seq_length = torch.randint(MIN_WORDS, SEQ_LEN-1, (BATCH_SIZE,))\n",
    "trg_seq_length = torch.randint(MIN_WORDS, SEQ_LEN-1, (BATCH_SIZE,))\n",
    "if SEQ_LEN - 1 not in src_seq_length:\n",
    "    src_seq_length[-1] = SEQ_LEN - 2\n",
    "if SEQ_LEN - 1 not in trg_seq_length:\n",
    "    trg_seq_length[-1] = SEQ_LEN - 2\n",
    "\n",
    "x = torch.randint(0+2, INPUT_DIM-2, size=(BATCH_SIZE, SEQ_LEN))\n",
    "x[:, 0] = 0\n",
    "for i, ind in enumerate(src_seq_length):\n",
    "    x[i, ind+1 ] = INPUT_DIM - 1\n",
    "    x[i, ind+2:] = SRC_PAD_IDX\n",
    "\n",
    "y = torch.randint(0+2, OUTPUT_DIM-2, size=(BATCH_SIZE, SEQ_LEN))\n",
    "y[:, 0] = 0\n",
    "for i, ind in enumerate(trg_seq_length):\n",
    "    y[i, ind+1 ] = OUTPUT_DIM - 1\n",
    "    y[i, ind+2:] = TRG_PAD_IDX\n",
    "\n",
    "print(x, x.shape, end='\\n\\n')\n",
    "print(y, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, \n",
    "                          enc_hid_dim, \n",
    "                          bidirectional=True,\n",
    "                          batch_first=True)\n",
    "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        H = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
    "        hidden = torch.tanh(self.fc(H))\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(INPUT_DIM, \n",
    "                  ENC_EMB_DIM, \n",
    "                  ENC_HID_DIM, \n",
    "                  DEC_HID_DIM, \n",
    "                  ENC_DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_outputs, hidden = encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 15, 128]), torch.Size([5, 64]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs.shape, hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = nn.Linear((ENC_HID_DIM * 2) + DEC_HID_DIM, DEC_HID_DIM)\n",
    "v    = nn.Linear(DEC_HID_DIM, 1, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 15)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = encoder_outputs.shape[0]\n",
    "src_len    = encoder_outputs.shape[1]\n",
    "batch_size, src_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 15, 64])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 15, 128])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 15, 192])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_input = torch.cat((hidden, encoder_outputs), dim=2)\n",
    "attn_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 15, 64])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy = torch.tanh(attn(attn_input))\n",
    "energy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0539, -0.0065,  0.0062,  0.0372, -0.0093,  0.0023, -0.0123, -0.0547,\n",
       "         -0.0239, -0.0520, -0.0222, -0.0278,  0.0077,  0.0225,  0.0639],\n",
       "        [-0.1007, -0.0163,  0.0256, -0.0813,  0.0054, -0.0546, -0.0751, -0.0746,\n",
       "         -0.0089,  0.0729,  0.0307, -0.0212, -0.0064,  0.0150,  0.0343],\n",
       "        [-0.0608, -0.0555, -0.0218,  0.0031,  0.0006,  0.0082, -0.0632, -0.0951,\n",
       "         -0.0731, -0.0216, -0.0165,  0.0403,  0.0202, -0.0054,  0.0102],\n",
       "        [-0.0029,  0.1008,  0.0611,  0.0713,  0.0479,  0.0121,  0.0158,  0.0386,\n",
       "          0.0447,  0.0643,  0.1064,  0.0596,  0.0050,  0.0535,  0.0291],\n",
       "        [-0.0200,  0.0215,  0.0154, -0.0228, -0.0933, -0.0283,  0.0089, -0.0378,\n",
       "         -0.0633, -0.0663, -0.0248,  0.0035,  0.0336, -0.0549, -0.0254]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = v(energy).squeeze(2)\n",
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0637, 0.0667, 0.0676, 0.0697, 0.0666, 0.0673, 0.0664, 0.0636, 0.0656,\n",
       "         0.0638, 0.0657, 0.0653, 0.0677, 0.0687, 0.0716],\n",
       "        [0.0612, 0.0666, 0.0695, 0.0624, 0.0681, 0.0641, 0.0628, 0.0629, 0.0671,\n",
       "         0.0729, 0.0698, 0.0663, 0.0673, 0.0688, 0.0701],\n",
       "        [0.0641, 0.0644, 0.0666, 0.0683, 0.0681, 0.0687, 0.0639, 0.0619, 0.0633,\n",
       "         0.0666, 0.0670, 0.0709, 0.0695, 0.0677, 0.0688],\n",
       "        [0.0634, 0.0703, 0.0676, 0.0683, 0.0667, 0.0643, 0.0646, 0.0661, 0.0665,\n",
       "         0.0678, 0.0707, 0.0675, 0.0639, 0.0671, 0.0654],\n",
       "        [0.0669, 0.0697, 0.0693, 0.0667, 0.0621, 0.0663, 0.0688, 0.0657, 0.0640,\n",
       "         0.0638, 0.0665, 0.0685, 0.0705, 0.0646, 0.0665]],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation = F.softmax(attention, dim=1)\n",
    "annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 15])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation = annotation.unsqueeze(1)\n",
    "annotation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 128])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted = torch.bmm(annotation, encoder_outputs)\n",
    "weighted.shape\n",
    "# (b, n, m) X (b, m, p) ==>> (b, n, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 160])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_input = torch.cat((embedded, weighted), dim=2)\n",
    "rnn_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Additive Self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 25,  4, 25, 21, 25,  9,  6, 29,  1,  1,  1,  1,  1,  1],\n",
       "        [ 0, 26,  7, 11,  7, 18, 11,  6, 12,  7, 29,  1,  1,  1,  1],\n",
       "        [ 0,  8,  8, 25,  9, 24, 17, 14, 16, 24, 21, 10, 24, 29,  1],\n",
       "        [ 0,  5, 25,  3, 17, 21, 17,  4, 25,  3, 15, 29,  1,  1,  1],\n",
       "        [ 0, 10,  7, 17, 23,  7,  9, 13,  8,  8,  7,  9, 20, 16, 29]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "SEQ_LEN     = 15\n",
    "BATCH_SIZE  = 5\n",
    "INPUT_DIM   = 30\n",
    "OUTPUT_DIM  = 37\n",
    "HID_DIM     = 256\n",
    "ENC_EMB_DIM = DEC_EMB_DIM = 32\n",
    "ENC_HID_DIM = DEC_HID_DIM = 64\n",
    "ENC_LAYERS  = DEC_LAYERS  = 3\n",
    "ENC_HEADS   = DEC_HEADS   = 8\n",
    "ENC_PF_DIM  = DEC_PF_DIM  = 512\n",
    "ENC_DROPOUT = DEC_DROPOUT = 0.1\n",
    "\n",
    "r = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = nn.Embedding(INPUT_DIM,  # vocab_size\n",
    "                     ENC_EMB_DIM # embedding_size\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(ENC_EMB_DIM,\n",
    "              ENC_HID_DIM, # hidden_size\n",
    "              num_layers=1,\n",
    "              batch_first=True,\n",
    "              bidirectional=True\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = nn.Linear(2 * ENC_HID_DIM, # num_directions*hidden_size\n",
    "                 DEC_HID_DIM,     # attention_dimension\n",
    "                 bias=False\n",
    "                )\n",
    "attn2 = nn.Linear(DEC_HID_DIM,    # attention_dimension\n",
    "                  r,              # keywords\n",
    "                                  # (different parts to be expected\n",
    "                                  #  from the sentence)\n",
    "                  bias=False\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tanh = nn.Tanh()\n",
    "sigmoid = nn.Sigmoid()\n",
    "attn_dist = nn.Softmax(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = nn.Sequential(\n",
    "    nn.Linear(r * ENC_HID_DIM, 2, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 2), # fc의 hidden_size, output_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded = embed(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 15, 32])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torch.nn.utils.rnn import pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = Variable(\n",
    "    torch.zeros(1*2, batch_size, ENC_HID_DIM)\n",
    ")\n",
    "cell = Variable(\n",
    "    torch.zeros(1*2, batch_size, ENC_HID_DIM)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 15, 32])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_pack_padded_sequence(): argument 'input' (position 1) must be Tensor, not Embedding",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-26a41f2a8e33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m packed = pack_padded_sequence(embed, \n\u001b[0;32m      2\u001b[0m                               \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                               batch_first=True)\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpacked\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\torch\\nn\\utils\\rnn.py\u001b[0m in \u001b[0;36mpack_padded_sequence\u001b[1;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m         \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pack_padded_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: _pack_padded_sequence(): argument 'input' (position 1) must be Tensor, not Embedding"
     ]
    }
   ],
   "source": [
    "packed = pack_padded_sequence(embed, \n",
    "                              (x != 1).sum(dim=1).tolist(), \n",
    "                              batch_first=True)\n",
    "packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "basic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
